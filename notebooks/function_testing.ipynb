{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8aa5a322-cb8a-46b1-98e0-ec215566611d",
   "metadata": {},
   "source": [
    "## load_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b09b7891-8a71-4353-8028-702a3d006578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from colorama import Fore, Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3becde0d-96df-4dec-b20c-c8f51a5f84a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import RAW_DATA_PATH, TEXT_FILE, RATES_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e2743ab-627d-4f99-8bd2-f48c1e831b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## load_raw_data ########\n",
    "# Description: import raw from a local folder into a dataframe\n",
    "# Args: folder path\n",
    "# Kwargs: N/A\n",
    "# Seps: defines local folder path as variable\n",
    "#       pull data using path variable\n",
    "# Output : tuple with two dataframes \n",
    "\n",
    "def load_raw_data():\n",
    "\n",
    "    # Load environment variables from .env file\n",
    "    load_dotenv(override=True)\n",
    "    \n",
    "    print(Fore.MAGENTA + \"\\nLoading raw data...\" + Style.RESET_ALL)\n",
    "    \n",
    "    # Debugging: Check if environment variables are loaded correctly\n",
    "    print(f\"RAW_DATA_PATH: {RAW_DATA_PATH}\")\n",
    "    print(f\"TEXT_FILE: {TEXT_FILE}\")\n",
    "    print(f\"RATES_FILE: {RATES_FILE}\")\n",
    "    \n",
    "    # Construct full file paths\n",
    "    text_data = os.path.join(RAW_DATA_PATH, TEXT_FILE)\n",
    "    rates_data = os.path.join(RAW_DATA_PATH, RATES_FILE)\n",
    "\n",
    "     # Debugging: Check if paths exist\n",
    "    if not os.path.exists(text_data):\n",
    "        raise FileNotFoundError(f\"Error: The text file was not found at {text_data}\")\n",
    "\n",
    "    if not os.path.exists(rates_data):\n",
    "        raise FileNotFoundError(f\"Error: The rates file was not found at {rates_data}\")\n",
    "\n",
    "    \n",
    "    text_df = pd.read_csv(text_data)\n",
    "    rates_df = pd.read_csv(rates_data)\n",
    "    \n",
    "    print(f\"Data loaded from {text_data, rates_data}\")\n",
    "    \n",
    "    return text_df, rates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62b47fb0-44e7-4389-b0b2-e9b42aa4039b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\n",
      "Loading raw data...\u001b[0m\n",
      "RAW_DATA_PATH: /home/antonio/code/aferri-git/FED-Predictor/data/raw\n",
      "TEXT_FILE: Fed_Scrape-2015-2023.csv\n",
      "RATES_FILE: US Fed Rate.csv\n",
      "Data loaded from ('/home/antonio/code/aferri-git/FED-Predictor/data/raw/Fed_Scrape-2015-2023.csv', '/home/antonio/code/aferri-git/FED-Predictor/data/raw/US Fed Rate.csv')\n",
      "   Unnamed: 0      Date  Type  \\\n",
      "0           0  20230412     0   \n",
      "1           1  20230412     0   \n",
      "2           2  20230412     0   \n",
      "3           3  20230412     0   \n",
      "4           4  20230412     0   \n",
      "\n",
      "                                                Text  \n",
      "0  The Federal Reserve on Wednesday released the ...  \n",
      "1  The minutes for each regularly scheduled meeti...  \n",
      "2  The minutes can be viewed on the Board's website.  \n",
      "3  For media inquiries, e-mail [email protected] ...  \n",
      "4  Minutes of the Federal Open Market Committee\\r...        Release Date   Time Actual Forecast Previous\n",
      "0    Nov 01, 2023  13:00  5.50%    5.50%    5.50%\n",
      "1    Sep 20, 2023  13:00  5.50%    5.50%    5.50%\n",
      "2    Jul 26, 2023  13:00  5.50%    5.50%    5.25%\n",
      "3    Jun 14, 2023  13:00  5.25%    5.25%    5.25%\n",
      "4    May 03, 2023  13:00  5.25%    5.25%    5.00%\n",
      "..            ...    ...    ...      ...      ...\n",
      "196  Dec 19, 1990  13:00  7.00%        -    7.25%\n",
      "197  Dec 07, 1990  13:00  7.25%        -    7.50%\n",
      "198  Nov 14, 1990  13:00  7.50%        -    7.75%\n",
      "199  Oct 29, 1990  13:00  7.75%        -    8.00%\n",
      "200  Jul 13, 1990  13:00  8.00%        -    8.25%\n",
      "\n",
      "[201 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "text_df, rates_df = load_raw_data()\n",
    "\n",
    "print(text_df.head(), rates_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0d5858-4621-47c6-86bf-152ad3b039a3",
   "metadata": {},
   "source": [
    "## adjust_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8456f4d3-849e-4be6-a938-6a3ed706ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_column_names(df, rename_dict=None):\n",
    "    \n",
    "    df.columns = df.columns.str.lower()\n",
    "    \n",
    "    if rename_dict:  # Only rename if a valid dictionary is provided\n",
    "        df = df.rename(columns=rename_dict)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e45ddf5e-0422-4530-9bbe-b7a1bf252d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = adjust_column_names(text_df)\n",
    "rates_df= adjust_column_names(rates_df, {'release date' : 'date', 'actual' : 'rate'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1e09996-32a9-44bf-afd7-9191a5bc1332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['unnamed: 0', 'date', 'type', 'text'], dtype='object')\n",
      "Index(['date', 'time', 'rate', 'forecast', 'previous'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(text_df.columns)\n",
    "print(rates_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdb55b2-955d-4072-820b-bfd1f9e59c00",
   "metadata": {},
   "source": [
    "## format_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03876ccd-dfa0-48e5-9050-e67de64cdab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_raw_data(\n",
    "    text_df, rates_df, \n",
    "    date='date',\n",
    "    rate='rate'\n",
    "):\n",
    "\n",
    "    try:\n",
    "        text_df[date] = pd.to_datetime(text_df[date], format='%Y%m%d')\n",
    "        rates_df[date] = pd.to_datetime(rates_df[date], format='%b %d, %Y')  # Note: specific format for rate dates\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error while converting date columns: {e}\")\n",
    "    \n",
    "    rates_df[rate] = rates_df[rate].str.rstrip('%').astype(float)\n",
    "\n",
    "    start_date_text_df = text_df[date].min()\n",
    "    rates_df = rates_df[rates_df[date] >= start_date_text_df]\n",
    "\n",
    "    return text_df, rates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdaefb82-a275-42b7-8306-5fae4d2a8567",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df, rates_df = format_raw_data(text_df, rates_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "951f29a2-5f8e-4728-bd5a-08b52f82b584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9974 entries, 0 to 9973\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   unnamed: 0  9974 non-null   int64         \n",
      " 1   date        9974 non-null   datetime64[ns]\n",
      " 2   type        9974 non-null   int64         \n",
      " 3   text        9974 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(2), object(1)\n",
      "memory usage: 311.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 72 entries, 0 to 71\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   date      72 non-null     datetime64[ns]\n",
      " 1   time      72 non-null     object        \n",
      " 2   rate      72 non-null     float64       \n",
      " 3   forecast  72 non-null     object        \n",
      " 4   previous  72 non-null     object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(3)\n",
      "memory usage: 3.4+ KB\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "print(text_df.info(), rates_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eff2a4-c725-43c7-a648-3fb871482a28",
   "metadata": {},
   "source": [
    "## sort_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0dfae1f1-c5c5-414c-9cbe-d14a4e6de4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dates(df, df_type, reference_df=None):\n",
    "    \n",
    "    # Ensure 'date' is a column (if already an index, reset it)\n",
    "    if 'date' in df.index:\n",
    "        df = df.reset_index()\n",
    "    \n",
    "    df = df.sort_values(by='date')  # Sort by date\n",
    "    \n",
    "    # If df_type is 'rates', filter based on reference_df (text_df)\n",
    "    if df_type == 'rates' and reference_df is not None:\n",
    "        start_date = reference_df['date'].min()  # Get earliest date from reference_df\n",
    "        df = df[df['date'] >= start_date]  # Filter df where date is >= start_date\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d065baf1-614f-4f95-ac5c-8ba74ff65408",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = sort_dates(text_df, 'text')\n",
    "rates_df = sort_dates(rates_df, 'rates', text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "621e7779-e81a-4871-8bfd-7d0b7f023098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      unnamed: 0       date  type  \\\n",
      "9973        9973 2015-01-07     0   \n",
      "9969        9969 2015-01-07     0   \n",
      "9972        9972 2015-01-07     0   \n",
      "9971        9971 2015-01-07     0   \n",
      "9970        9970 2015-01-07     0   \n",
      "\n",
      "                                                   text  \n",
      "9973  \\r\\n       For media inquiries, call 202-452-2...  \n",
      "9969  \\r\\n       The Federal Reserve Board and the F...  \n",
      "9972  \\nMinutes of the Federal Open Market Committee...  \n",
      "9971  \\r\\n       FOMC minutes can be viewed on the B...  \n",
      "9970  \\r\\n       The minutes for each regularly sche...  \n"
     ]
    }
   ],
   "source": [
    "print(text_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d66fc5b-d41a-4194-bb2b-a18688f97248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date   time  rate forecast previous\n",
      "71 2015-01-28  14:00  0.25    0.25%    0.25%\n",
      "70 2015-03-18  13:00  0.25    0.25%    0.25%\n",
      "69 2015-04-29  13:00  0.25    0.25%    0.25%\n",
      "68 2015-06-17  13:00  0.25    0.25%    0.25%\n",
      "67 2015-07-29  13:00  0.25    0.25%    0.25%\n"
     ]
    }
   ],
   "source": [
    "print(rates_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222c8728-eeb8-432a-a73a-c0246bd182f2",
   "metadata": {},
   "source": [
    "## text_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c96c259-8872-45c6-b0dc-31cc267bfa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_encode(df, column, df_type):\n",
    "    \n",
    "    # Ensure the column exists before applying any transformation\n",
    "    if column not in df.columns:\n",
    "        raise KeyError(f\"Column '{column}' does not exist in the {df_type} dataframe.\")\n",
    "    \n",
    "    if df_type == 'text': # check what df_type it is\n",
    "        df['type_text'] = df[column].apply(lambda x: 'statement' if x == 0 else 'minutes')\n",
    "    \n",
    "    elif df_type == 'rates':\n",
    "        df['rate_change'] = df[column].diff()  # Calculate the difference in rate values\n",
    "        df['rate_change_text'] = df['rate_change'].apply(lambda x: 'up' if x > 0 else ('down' if x < 0 else 'no change')).astype(str)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Invalid df_type. Choose 'text' or 'rates'.\")\n",
    "\n",
    "    print(f\"{df_type} dataframe after encoding:\\n\", df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4c67a5c-d7d5-42a4-9a7c-0ac5a77b565d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text dataframe after encoding:\n",
      "       unnamed: 0       date  type  \\\n",
      "9973        9973 2015-01-07     0   \n",
      "9969        9969 2015-01-07     0   \n",
      "9972        9972 2015-01-07     0   \n",
      "9971        9971 2015-01-07     0   \n",
      "9970        9970 2015-01-07     0   \n",
      "\n",
      "                                                   text  type_text  \n",
      "9973  \\r\\n       For media inquiries, call 202-452-2...  statement  \n",
      "9969  \\r\\n       The Federal Reserve Board and the F...  statement  \n",
      "9972  \\nMinutes of the Federal Open Market Committee...  statement  \n",
      "9971  \\r\\n       FOMC minutes can be viewed on the B...  statement  \n",
      "9970  \\r\\n       The minutes for each regularly sche...  statement  \n",
      "rates dataframe after encoding:\n",
      "          date   time  rate forecast previous  rate_change rate_change_text\n",
      "71 2015-01-28  14:00  0.25    0.25%    0.25%          NaN        no change\n",
      "70 2015-03-18  13:00  0.25    0.25%    0.25%          0.0        no change\n",
      "69 2015-04-29  13:00  0.25    0.25%    0.25%          0.0        no change\n",
      "68 2015-06-17  13:00  0.25    0.25%    0.25%          0.0        no change\n",
      "67 2015-07-29  13:00  0.25    0.25%    0.25%          0.0        no change\n"
     ]
    }
   ],
   "source": [
    "text_df = text_encode(text_df, 'type', 'text')\n",
    "rates_df = text_encode (rates_df, 'rate', 'rates')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7625581-ba88-4609-b32d-d4c426fe5e49",
   "metadata": {},
   "source": [
    "## sliding_window and group_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce8a001b-defb-426d-8060-e06e1aadc136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e259ab99-487d-4569-a79e-8b584ab770e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_text(rate_date, text_df, date_diff):\n",
    "    window_size = timedelta(days=date_diff)\n",
    "\n",
    "    # Filter texts that occurred before the rate decision\n",
    "    valid_texts = text_df[text_df['date'] < rate_date]\n",
    "\n",
    "    # Apply sliding window: Get texts within the specified window size before rate_date\n",
    "    texts_in_window = valid_texts[valid_texts['date'] >= rate_date - window_size]\n",
    "\n",
    "    # Combine the texts\n",
    "    grouped_texts = ' '.join(texts_in_window['text'])\n",
    "    \n",
    "    return grouped_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "63825504-ef0f-4c8b-a821-4c13bf84c6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(rates_df, text_df):\n",
    "    \n",
    "    rates_df = rates_df.copy()\n",
    "    \n",
    "    # Calculate the difference between consecutive rate decisions to determine dynamic window size\n",
    "    rates_df['next_date'] = rates_df['date'].shift(-1)\n",
    "    rates_df['date_diff'] = (rates_df['next_date'] - rates_df['date']).dt.days\n",
    "    \n",
    "    # Corrects for NaNs since we are subtracting time deltas\n",
    "    rates_df['date_diff'] = rates_df['date_diff'].fillna(0).astype(int)\n",
    "\n",
    "    # isolate statements and minutes as they occurr at different times relative to previous decisions\n",
    "    statement_df = text_df[text_df['type_text'] == 'statement']\n",
    "    minutes_df = text_df[text_df['type_text'] == 'minutes']    \n",
    "\n",
    "    pairing_data  = []\n",
    "\n",
    "    for _, rate_row in rates_df.iterrows():\n",
    "        rate_date = rate_row['date']\n",
    "        rate = rate_row['rate_change_text']\n",
    "        date_diff = rate_row['date_diff']\n",
    "        \n",
    "        grouped_statements = group_text(rate_date, statement_df, date_diff)\n",
    "        grouped_minutes = group_text(rate_date, minutes_df, date_diff)\n",
    "    \n",
    "        # Add the data to pairing_df\n",
    "        pairing_data.append({\n",
    "            'decision': rate,\n",
    "            'date': rate_date,\n",
    "            'grouped_statements': grouped_statements,\n",
    "            'grouped_minutes': grouped_minutes,\n",
    "            'window_size_days': date_diff  # Store the dynamic window size for reference\n",
    "        })\n",
    "\n",
    "    pairing_df = pd.DataFrame(pairing_data)\n",
    "    pairing_df = pairing_df.set_index(\"date\")\n",
    "    \n",
    "    return pairing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d26dc8e-46a0-42f1-a402-6b73aeff0a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             decision                                 grouped_statements  \\\n",
      "date                                                                       \n",
      "2015-01-28  no change  \\r\\n       For media inquiries, call 202-452-2...   \n",
      "2015-03-18  no change  \\nSubmission of Tender\\nParticipants must subm...   \n",
      "2015-04-29  no change  \\r\\n       Information received since the Fede...   \n",
      "2015-06-17  no change  \\r\\n       The Federal Open Market Committee o...   \n",
      "2015-07-29  no change  \\r\\n      Voting for the FOMC monetary policy ...   \n",
      "\n",
      "                                              grouped_minutes  \\\n",
      "date                                                            \n",
      "2015-01-28                                                      \n",
      "2015-03-18                                                      \n",
      "2015-04-29  Michael Dotsey, Craig S. Hakkio, Evan F. Koeni...   \n",
      "2015-06-17                                                      \n",
      "2015-07-29  Glenn Follette and Paul A. Smith, Assistant Di...   \n",
      "\n",
      "            window_size_days  \n",
      "date                          \n",
      "2015-01-28                49  \n",
      "2015-03-18                42  \n",
      "2015-04-29                49  \n",
      "2015-06-17                42  \n",
      "2015-07-29                50  \n"
     ]
    }
   ],
   "source": [
    "pairing_df = sliding_window(rates_df, text_df)\n",
    "print(pairing_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df30a37-9244-493b-81db-25a27f8cf139",
   "metadata": {},
   "source": [
    "## ordinal_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a4c31b9-353c-4877-992f-1dd8bdb6f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a020306-643d-419f-b953-486ac195204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_encode(df, column):\n",
    "    \n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    df[f'{column}_encoded'] = ordinal_encoder.fit_transform(df[[column]]).astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae2e9d6b-9883-4d51-864e-aac108ebd8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "2015-01-28    1\n",
      "2015-03-18    1\n",
      "2015-04-29    1\n",
      "2015-06-17    1\n",
      "2015-07-29    1\n",
      "Name: decision_encoded, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pairing_df = ordinal_encode (pairing_df, 'decision')\n",
    "print(pairing_df['decision_encoded'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55846154-5608-4967-9af2-926b6bf0afd4",
   "metadata": {},
   "source": [
    "## FinBERT_vectorization and finalize_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18cc0d53-9484-4994-8a64-821e990e11b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b1d0008a-7dae-43ce-991a-76166f48693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FinBERT_vectorizaion(text):\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "    model = AutoModel.from_pretrained(\"ProsusAI/finbert\")\n",
    "    \n",
    "    # Ensure text is not empty or NaN\n",
    "    if pd.isna(text) or text.strip() == \"\":\n",
    "        return np.zeros((768,),dtype=np.float32)  # Return a zero-vector if input is empty or NaN\n",
    "    \n",
    "    # Proceed with tokenization and embedding generation\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    return outputs.last_hidden_state[:, 0, :].squeeze().numpy().astype(np.float32)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "72ff8574-35f8-4c59-9777-5cb520631fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_df(df):\n",
    "    \n",
    "    # Vectorize statements and minutes\n",
    "    df['statement_vectorized'] = df['grouped_statements'].apply(lambda x: np.array(FinBERT_vectorizaion(str(x)), dtype=np.float32))\n",
    "    df['minutes_vectorized'] = df['grouped_minutes'].apply(lambda x: np.array(FinBERT_vectorizaion(str(x)), dtype=np.float32))\n",
    "\n",
    "    # Combine the two vectors into one\n",
    "    df['combined_vectorization'] = df.apply(\n",
    "        lambda row: np.hstack((\n",
    "            row['statement_vectorized'],  # Ensure this is a numpy array\n",
    "            row['minutes_vectorized'] if isinstance(row['minutes_vectorized'], np.ndarray) else np.zeros(768, dtype=np.float32)\n",
    "        )),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Make sure the 'combined_vectorization' column is stored as a numpy array of dtype float32\n",
    "    df['combined_vectorization'] = df['combined_vectorization'].apply(lambda x: np.array(x, dtype=np.float32))\n",
    "    \n",
    "    # Debugging: Check data type after processing\n",
    "    print(df['combined_vectorization'].apply(type).head(3))  # Should show <class 'numpy.ndarray'>\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b6913490-f162-4805-9185-2136ca157e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 13:19:31.944047: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-10 13:19:32.547710: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-10 13:19:32.607173: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-02-10 13:19:32.607191: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-02-10 13:19:32.696720: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-10 13:19:33.581368: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-02-10 13:19:33.581526: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-02-10 13:19:33.581535: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "2015-01-28    <class 'numpy.ndarray'>\n",
      "2015-03-18    <class 'numpy.ndarray'>\n",
      "2015-04-29    <class 'numpy.ndarray'>\n",
      "Name: combined_vectorization, dtype: object\n"
     ]
    }
   ],
   "source": [
    "final_df = finalize_df(pairing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "11edf200-a2d7-4fc5-9734-5e8d4fa4399a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "2015-01-28    [-0.24246012, 0.67152435, -0.20416914, -0.2890...\n",
      "2015-03-18    [-0.07346612, 0.82941, -0.24438372, -0.5677416...\n",
      "2015-04-29    [-0.092187196, -0.2836279, -0.6326303, -0.3542...\n",
      "2015-06-17    [0.060003556, 0.84255415, -0.253191, -0.209660...\n",
      "2015-07-29    [0.06376937, -0.35077733, -0.35831827, -0.2351...\n",
      "Name: combined_vectorization, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(final_df['combined_vectorization'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463051d3-297c-420a-a692-d2f6b6ee0bda",
   "metadata": {},
   "source": [
    "## train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f15c5dda-5aba-4681-ae95-c01bbe54b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "af00d1b3-2244-4d09-84ec-969c0a00eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_train_test_split(df, test_size=0.2, random_state=42):\n",
    "    \"\"\" Splits the dataset into training and testing sets. \"\"\"\n",
    "   \n",
    "    # Convert stringified arrays back to real NumPy arrays\n",
    "    df['combined_vectorization'] = df['combined_vectorization'].apply(lambda x: np.array(ast.literal_eval(x), dtype=np.float32) if isinstance(x, str) else x)\n",
    "\n",
    "    # Stack the arrays to create the feature matrix\n",
    "    X = np.vstack(df['combined_vectorization'].values)\n",
    "    y = df['decision_encoded'].values\n",
    "\n",
    "    # Split the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test  # ✅ Returns only 4 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b6468be6-0507-4d79-bffa-032bbce05add",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = custom_train_test_split(final_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e032e501-e3b9-401f-a3e5-ce949934cf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.4603853   0.1941262  -0.56941366 ... -0.11998674  1.0199955\n",
      "   0.5946898 ]\n",
      " [ 0.30797532 -0.3074921  -0.43068966 ...  0.05326387  0.83187574\n",
      "   0.34394997]\n",
      " [-0.22082192  0.5572233   0.25929168 ... -0.17048459  0.4922418\n",
      "   0.46881706]\n",
      " ...\n",
      " [-0.9463986   0.479746   -0.1653099  ... -0.50802386 -0.38364428\n",
      "   0.5584152 ]\n",
      " [-0.12968168 -0.0050654  -0.41801387 ... -0.47364542  0.03962266\n",
      "   0.66211003]\n",
      " [-0.01522618  0.37421858 -0.64247054 ... -0.06257439  0.06237637\n",
      "   0.34195045]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2f26c6e3-d14c-42c4-a114-26429b8fab40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 2 1 1 1 2 2 1 0 1 1 1 2 2 2 1 1 2 1 2 0 1 1 1 0 2 1 1 2 2 0 1 1\n",
      " 1 2 2 1 1 1 2 0 2 1 2 1 1 1 1 2 1 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc1d02c-11f6-43eb-af74-204e36ee35b5",
   "metadata": {},
   "source": [
    "## class_weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5a554fbc-52a3-4250-a2ab-45a5232372e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_weighting (y_train):\n",
    "\n",
    "    # Convert y_train to a Pandas Series to use value_counts\n",
    "    y_train = pd.Series(y_train)\n",
    "    \n",
    "    # Count occurrences in y_train\n",
    "    class_counts = y_train.value_counts().sort_index().values  # Ensure ordering is correct\n",
    "\n",
    "    # Compute class weights\n",
    "    class_weights = torch.tensor([1 / count for count in class_counts], dtype=torch.float32)\n",
    "    \n",
    "    return class_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "68c6a6dd-3504-4991-bf03-c8483cd22d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weighting(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8788b1e6-0895-43f5-bfd9-b992b06f5b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2000, 0.0294, 0.0556])\n"
     ]
    }
   ],
   "source": [
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829faf23-8fad-4ecf-bed8-e3f74b5faffb",
   "metadata": {},
   "source": [
    "## tensor_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7484a4de-efd3-48b8-9407-29556b7ba57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_conversion(X_train, y_train):\n",
    "    \n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    # BiLSTM will need 3D tensors. our tensors only have 2Ds for X\n",
    "    # conversely, only 1D tensor for y with integer data, and not float\n",
    "    X_train_tensor = X_train_tensor.unsqueeze(1)\n",
    "    \n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "    \n",
    "    return X_train_tensor, y_train_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0a868d9e-35a1-4bc1-8eeb-d7ba5e06c2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor, y_train_tensor = tensor_conversion(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "07f750e5-0852-458a-99ed-a054a0be820d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([57, 1, 1536])\n",
      "torch.Size([57])\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tensor.shape)\n",
    "print(y_train_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3feb6fb9-ed10-4b57-ad49-cddb25a9e6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 1, 1536])\n",
      "torch.Size([15])\n"
     ]
    }
   ],
   "source": [
    "X_test_tensor, y_test_tensor = tensor_conversion(X_test, y_test)\n",
    "print(X_test_tensor.shape)\n",
    "print(y_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9f90e0-359a-46b3-82ff-9fda134a90e1",
   "metadata": {},
   "source": [
    "## initialize_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "06cf09dd-6240-4119-88e0-d2cb6b5fa2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from params import HIDDEN_DIM, OUTPUT_DIM, K, LEARNING_RATE, RANDOM_STATE, EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "62d370f7-8b2b-4e7d-85d4-0fb2015c1cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = X_train.shape[1]  # Same as embedding size\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = 3  # For multiclass classification (up, down, no change)\n",
    "K = 5 \n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 10\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d901d6d3-485e-4074-98ba-63d38d601c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # Multiply by 2 for bidirectional\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        last_out = lstm_out[:, -1, :]  # Take the last time step's output\n",
    "        return self.fc(self.relu(last_out))\n",
    "\n",
    "\n",
    "def initialize_model(X_train, hidden_dim = HIDDEN_DIM, output_dim = OUTPUT_DIM):\n",
    "    \n",
    "    input_dim = X_train.shape[1]\n",
    "    \n",
    "    model = BiLSTM(input_dim, hidden_dim, output_dim)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "694d313c-8c96-4e30-8c58-b871cbea0176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM(\n",
      "  (lstm): LSTM(1536, 128, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = initialize_model(X_train, HIDDEN_DIM, OUTPUT_DIM)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e155d84-d6a1-4ae8-8c4e-1ca47ac6577c",
   "metadata": {},
   "source": [
    "## compile_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7c239f5a-dc8b-48f3-856a-25448df64278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(y_train, model, learning_rate=LEARNING_RATE):\n",
    "    \n",
    "    class_weights = class_weighting (y_train)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    return criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "49ea638c-0b65-47d3-9544-0bf7392a1277",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion, optimizer = compile_model(y_train, model, learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "affbf6a2-cb67-4624-96b4-f7fc685072cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossEntropyLoss() Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2909dc0-0bac-4e60-a0f0-1fa1ee58befe",
   "metadata": {},
   "source": [
    "## evaluate_model and train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "230f054e-128d-4c8b-a71f-62811f6ddbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test_tensor, y_test_tensor):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient computation for efficiency\n",
    "        outputs = model(X_test_tensor)  # Get the model's output\n",
    "\n",
    "        logits = outputs  # These are the raw predictions (logits)\n",
    "\n",
    "        # Get the predicted class (highest logit)\n",
    "        predicted_labels = torch.argmax(logits, dim=1)\n",
    "        \n",
    "    # Compute accuracy by comparing predicted labels to true labels\n",
    "    accuracy = accuracy_score(y_test_tensor.numpy(), predicted_labels.numpy())\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d655899d-33bc-40d7-a7da-2e16bacd4ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate_model(model, X_test_tensor, y_test_tensor)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "95fb17d6-a813-45d0-a218-c1d3910aae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train_tensor, y_train_tensor, y_train, n_splits=K):\n",
    "    \n",
    "    kf = KFold(n_splits=K, shuffle=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "    fold_accuracies =[]\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_tensor, y_train_tensor)):\n",
    "        print(f\"Training fold {fold + 1}/{K}...\")\n",
    "\n",
    "        # Split data into training and validation sets for this fold\n",
    "        X_train_fold, X_val_fold = X_train_tensor[train_idx], X_train_tensor[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train_tensor[train_idx], y_train_tensor[val_idx]\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        X_train_fold_tensor = torch.tensor(X_train_fold, dtype=torch.float32)\n",
    "        y_train_fold_tensor = torch.tensor(y_train_fold, dtype=torch.long)\n",
    "        X_val_fold_tensor = torch.tensor(X_val_fold, dtype=torch.float32)\n",
    "        y_val_fold_tensor = torch.tensor(y_val_fold, dtype=torch.long)\n",
    "\n",
    "        # Initialize the model, criterion, and optimizer\n",
    "        model = initialize_model(X_train, hidden_dim=128, output_dim=3)\n",
    "        criterion, optimizer = compile_model(y_train, model, learning_rate = LEARNING_RATE)\n",
    "\n",
    "        # Train the model on this fold\n",
    "        model.train()  # Set model to training mode\n",
    "        for epoch in range(EPOCHS):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train_fold_tensor)\n",
    "            loss = criterion(outputs, y_train_fold_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        # Evaluate the model on the validation set\n",
    "        accuracy = evaluate_model(model, X_val_fold_tensor, y_val_fold_tensor)\n",
    "        print(f\"Fold {fold + 1} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # Save the accuracy for this fold\n",
    "        fold_accuracies.append(accuracy)\n",
    "\n",
    "        # Calculate average accuracy across all folds\n",
    "        average_accuracy = np.mean(fold_accuracies)\n",
    "        print(f\"\\nAverage Cross-Validation Accuracy: {average_accuracy:.4f}\")\n",
    "\n",
    "    return model, average_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3a218b0d-8697-49ef-a5d2-b18bcc9e1d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48266/161865244.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_fold_tensor = torch.tensor(X_train_fold, dtype=torch.float32)\n",
      "/tmp/ipykernel_48266/161865244.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train_fold_tensor = torch.tensor(y_train_fold, dtype=torch.long)\n",
      "/tmp/ipykernel_48266/161865244.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val_fold_tensor = torch.tensor(X_val_fold, dtype=torch.float32)\n",
      "/tmp/ipykernel_48266/161865244.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_val_fold_tensor = torch.tensor(y_val_fold, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Accuracy: 0.4167\n",
      "\n",
      "Average Cross-Validation Accuracy: 0.4167\n",
      "Training fold 2/5...\n",
      "Fold 2 Accuracy: 0.4167\n",
      "\n",
      "Average Cross-Validation Accuracy: 0.4167\n",
      "Training fold 3/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48266/161865244.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_fold_tensor = torch.tensor(X_train_fold, dtype=torch.float32)\n",
      "/tmp/ipykernel_48266/161865244.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train_fold_tensor = torch.tensor(y_train_fold, dtype=torch.long)\n",
      "/tmp/ipykernel_48266/161865244.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val_fold_tensor = torch.tensor(X_val_fold, dtype=torch.float32)\n",
      "/tmp/ipykernel_48266/161865244.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_val_fold_tensor = torch.tensor(y_val_fold, dtype=torch.long)\n",
      "/tmp/ipykernel_48266/161865244.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_fold_tensor = torch.tensor(X_train_fold, dtype=torch.float32)\n",
      "/tmp/ipykernel_48266/161865244.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train_fold_tensor = torch.tensor(y_train_fold, dtype=torch.long)\n",
      "/tmp/ipykernel_48266/161865244.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val_fold_tensor = torch.tensor(X_val_fold, dtype=torch.float32)\n",
      "/tmp/ipykernel_48266/161865244.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_val_fold_tensor = torch.tensor(y_val_fold, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Accuracy: 0.3636\n",
      "\n",
      "Average Cross-Validation Accuracy: 0.3990\n",
      "Training fold 4/5...\n",
      "Fold 4 Accuracy: 0.8182\n",
      "\n",
      "Average Cross-Validation Accuracy: 0.5038\n",
      "Training fold 5/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48266/161865244.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_fold_tensor = torch.tensor(X_train_fold, dtype=torch.float32)\n",
      "/tmp/ipykernel_48266/161865244.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train_fold_tensor = torch.tensor(y_train_fold, dtype=torch.long)\n",
      "/tmp/ipykernel_48266/161865244.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val_fold_tensor = torch.tensor(X_val_fold, dtype=torch.float32)\n",
      "/tmp/ipykernel_48266/161865244.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_val_fold_tensor = torch.tensor(y_val_fold, dtype=torch.long)\n",
      "/tmp/ipykernel_48266/161865244.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_fold_tensor = torch.tensor(X_train_fold, dtype=torch.float32)\n",
      "/tmp/ipykernel_48266/161865244.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train_fold_tensor = torch.tensor(y_train_fold, dtype=torch.long)\n",
      "/tmp/ipykernel_48266/161865244.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val_fold_tensor = torch.tensor(X_val_fold, dtype=torch.float32)\n",
      "/tmp/ipykernel_48266/161865244.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_val_fold_tensor = torch.tensor(y_val_fold, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Accuracy: 0.5455\n",
      "\n",
      "Average Cross-Validation Accuracy: 0.5121\n",
      "BiLSTM(\n",
      "  (lstm): LSTM(1536, 128, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
      "  (relu): ReLU()\n",
      ") 0.5121212121212121\n"
     ]
    }
   ],
   "source": [
    "model, average_accuracy = train_model(X_train_tensor, y_train_tensor, y_train, n_splits=K)\n",
    "print(model, average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165776f8-48b1-4d14-8a92-e7b39c915b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FED-Predictor",
   "language": "python",
   "name": "fed-predictor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
