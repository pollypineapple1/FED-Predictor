{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8aa5a322-cb8a-46b1-98e0-ec215566611d",
   "metadata": {},
   "source": [
    "## load_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b09b7891-8a71-4353-8028-702a3d006578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from colorama import Fore, Style\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3becde0d-96df-4dec-b20c-c8f51a5f84a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_PATH: /home/antonio/code/aferri-git/FED-Predictor\n",
      "DATA_DIR: data/raw\n",
      "TEXT_FILE: Fed_Scrape-2015-2023.csv\n",
      "RATES_FILE: US Fed Rate.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Print out the environment variables to make sure they're loaded\n",
    "base_path = os.getenv(\"BASE_PATH\")\n",
    "data_dir = os.getenv(\"DATA_DIR\")\n",
    "text_file = os.getenv(\"TEXT_FILE\")\n",
    "rates_file = os.getenv(\"RATES_FILE\")\n",
    "\n",
    "print(\"BASE_PATH:\", base_path)\n",
    "print(\"DATA_DIR:\", data_dir)\n",
    "print(\"TEXT_FILE:\", text_file)\n",
    "print(\"RATES_FILE:\", rates_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbfb6b1a-e443-42c5-ba56-7d57bdaedc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/antonio/code/aferri-git/FED-Predictor/data/raw/Fed_Scrape-2015-2023.csv\n",
      "/home/antonio/code/aferri-git/FED-Predictor/data/raw/US Fed Rate.csv\n"
     ]
    }
   ],
   "source": [
    "TEXT_DATA = os.path.join(base_path, data_dir, text_file)\n",
    "RATES_DATA = os.path.join(base_path, data_dir, rates_file)\n",
    "\n",
    "print(TEXT_DATA)\n",
    "print(RATES_DATA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e2743ab-627d-4f99-8bd2-f48c1e831b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## load_raw_data ########\n",
    "# Description: import raw from a local folder into a dataframe\n",
    "# Args: folder path\n",
    "# Kwargs: N/A\n",
    "# Seps: defines local folder path as variable\n",
    "#       pull data using path variable\n",
    "# Output : tuple with two dataframes \n",
    "\n",
    "def load_raw_data():\n",
    "\n",
    "    # Load environment variables from .env file\n",
    "    load_dotenv(override=True)\n",
    "    \n",
    "    print(Fore.MAGENTA + \"\\nLoading raw data...\" + Style.RESET_ALL)\n",
    "\n",
    "    base_path = os.getenv(\"BASE_PATH\")\n",
    "    data_dir = os.getenv(\"DATA_DIR\")\n",
    "    text_file = os.getenv(\"TEXT_FILE\")\n",
    "    rates_file = os.getenv(\"RATES_FILE\")\n",
    "    \n",
    "    # Construct full file paths\n",
    "    TEXT_DATA = os.path.join(base_path, data_dir, text_file)\n",
    "    RATES_DATA = os.path.join(base_path, data_dir, rates_file)\n",
    "\n",
    "    \n",
    "     # Debugging: Check if paths exist\n",
    "    if not os.path.exists(TEXT_DATA):\n",
    "        raise FileNotFoundError(f\"Error: The text file was not found at {TEXT_DATA}\")\n",
    "\n",
    "    if not os.path.exists(RATES_DATA):\n",
    "        raise FileNotFoundError(f\"Error: The rates file was not found at {RATES_DATA}\")\n",
    "\n",
    "    \n",
    "    text_df = pd.read_csv(TEXT_DATA)\n",
    "    rates_df = pd.read_csv(RATES_DATA)\n",
    "    \n",
    "    print(f\"Data loaded from {TEXT_DATA, RATES_DATA}\")\n",
    "    \n",
    "    return text_df, rates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62b47fb0-44e7-4389-b0b2-e9b42aa4039b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\n",
      "Loading raw data...\u001b[0m\n",
      "Data loaded from ('/home/antonio/code/aferri-git/FED-Predictor/data/raw/Fed_Scrape-2015-2023.csv', '/home/antonio/code/aferri-git/FED-Predictor/data/raw/US Fed Rate.csv')\n",
      "   Unnamed: 0      Date  Type  \\\n",
      "0           0  20230412     0   \n",
      "1           1  20230412     0   \n",
      "2           2  20230412     0   \n",
      "3           3  20230412     0   \n",
      "4           4  20230412     0   \n",
      "\n",
      "                                                Text  \n",
      "0  The Federal Reserve on Wednesday released the ...  \n",
      "1  The minutes for each regularly scheduled meeti...  \n",
      "2  The minutes can be viewed on the Board's website.  \n",
      "3  For media inquiries, e-mail [email protected] ...  \n",
      "4  Minutes of the Federal Open Market Committee\\r...        Release Date   Time Actual Forecast Previous\n",
      "0    Nov 01, 2023  13:00  5.50%    5.50%    5.50%\n",
      "1    Sep 20, 2023  13:00  5.50%    5.50%    5.50%\n",
      "2    Jul 26, 2023  13:00  5.50%    5.50%    5.25%\n",
      "3    Jun 14, 2023  13:00  5.25%    5.25%    5.25%\n",
      "4    May 03, 2023  13:00  5.25%    5.25%    5.00%\n",
      "..            ...    ...    ...      ...      ...\n",
      "196  Dec 19, 1990  13:00  7.00%        -    7.25%\n",
      "197  Dec 07, 1990  13:00  7.25%        -    7.50%\n",
      "198  Nov 14, 1990  13:00  7.50%        -    7.75%\n",
      "199  Oct 29, 1990  13:00  7.75%        -    8.00%\n",
      "200  Jul 13, 1990  13:00  8.00%        -    8.25%\n",
      "\n",
      "[201 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "text_df, rates_df = load_raw_data()\n",
    "\n",
    "print(text_df.head(), rates_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0d5858-4621-47c6-86bf-152ad3b039a3",
   "metadata": {},
   "source": [
    "## adjust_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8456f4d3-849e-4be6-a938-6a3ed706ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_column_names(df, rename_dict=None):\n",
    "    \n",
    "    df.columns = df.columns.str.lower()\n",
    "    \n",
    "    if rename_dict:  # Only rename if a valid dictionary is provided\n",
    "        df = df.rename(columns=rename_dict)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e45ddf5e-0422-4530-9bbe-b7a1bf252d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = adjust_column_names(text_df)\n",
    "rates_df= adjust_column_names(rates_df, {'release date' : 'date', 'actual' : 'rate'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1e09996-32a9-44bf-afd7-9191a5bc1332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['unnamed: 0', 'date', 'type', 'text'], dtype='object')\n",
      "Index(['date', 'time', 'rate', 'forecast', 'previous'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(text_df.columns)\n",
    "print(rates_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdb55b2-955d-4072-820b-bfd1f9e59c00",
   "metadata": {},
   "source": [
    "## format_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03876ccd-dfa0-48e5-9050-e67de64cdab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_raw_data(\n",
    "    text_df, rates_df, \n",
    "    date='date',\n",
    "    rate='rate'\n",
    "):\n",
    "\n",
    "    text_df[date] = pd.to_datetime(text_df[date], format='%Y%m%d')\n",
    "    rates_df[date] = pd.to_datetime(rates_df[date], format='%b %d, %Y')\n",
    "\n",
    "    rates_df[rate] = rates_df[rate].str.rstrip('%').astype(float)\n",
    "\n",
    "    start_date_text_df = text_df[date].min()\n",
    "    rates_df = rates_df[rates_df[date] >= start_date_text_df]\n",
    "\n",
    "    return text_df, rates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cdaefb82-a275-42b7-8306-5fae4d2a8567",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df, rates_df = format_raw_data(text_df, rates_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "951f29a2-5f8e-4728-bd5a-08b52f82b584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9974 entries, 0 to 9973\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   unnamed: 0  9974 non-null   int64         \n",
      " 1   date        9974 non-null   datetime64[ns]\n",
      " 2   type        9974 non-null   int64         \n",
      " 3   text        9974 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(2), object(1)\n",
      "memory usage: 311.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 72 entries, 0 to 71\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   date      72 non-null     datetime64[ns]\n",
      " 1   time      72 non-null     object        \n",
      " 2   rate      72 non-null     float64       \n",
      " 3   forecast  72 non-null     object        \n",
      " 4   previous  72 non-null     object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(3)\n",
      "memory usage: 3.4+ KB\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "print(text_df.info(), rates_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eff2a4-c725-43c7-a648-3fb871482a28",
   "metadata": {},
   "source": [
    "## sort_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0dfae1f1-c5c5-414c-9cbe-d14a4e6de4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dates(df, df_type, reference_df=None):\n",
    "    \n",
    "    # Ensure 'date' is a column (if already an index, reset it)\n",
    "    if 'date' in df.index:\n",
    "        df = df.reset_index()\n",
    "    \n",
    "    df = df.sort_values(by='date')  # Sort by date\n",
    "    \n",
    "    # If df_type is 'rates', filter based on reference_df (text_df)\n",
    "    if df_type == 'rates' and reference_df is not None:\n",
    "        start_date = reference_df['date'].min()  # Get earliest date from reference_df\n",
    "        df = df[df['date'] >= start_date]  # Filter df where date is >= start_date\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d065baf1-614f-4f95-ac5c-8ba74ff65408",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = sort_dates(text_df, 'text')\n",
    "rates_df = sort_dates(rates_df, 'rates', text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "621e7779-e81a-4871-8bfd-7d0b7f023098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      unnamed: 0       date  type  \\\n",
      "9973        9973 2015-01-07     0   \n",
      "9969        9969 2015-01-07     0   \n",
      "9972        9972 2015-01-07     0   \n",
      "9971        9971 2015-01-07     0   \n",
      "9970        9970 2015-01-07     0   \n",
      "\n",
      "                                                   text  \n",
      "9973  \\r\\n       For media inquiries, call 202-452-2...  \n",
      "9969  \\r\\n       The Federal Reserve Board and the F...  \n",
      "9972  \\nMinutes of the Federal Open Market Committee...  \n",
      "9971  \\r\\n       FOMC minutes can be viewed on the B...  \n",
      "9970  \\r\\n       The minutes for each regularly sche...  \n"
     ]
    }
   ],
   "source": [
    "print(text_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d66fc5b-d41a-4194-bb2b-a18688f97248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date   time  rate forecast previous\n",
      "71 2015-01-28  14:00  0.25    0.25%    0.25%\n",
      "70 2015-03-18  13:00  0.25    0.25%    0.25%\n",
      "69 2015-04-29  13:00  0.25    0.25%    0.25%\n",
      "68 2015-06-17  13:00  0.25    0.25%    0.25%\n",
      "67 2015-07-29  13:00  0.25    0.25%    0.25%\n"
     ]
    }
   ],
   "source": [
    "print(rates_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222c8728-eeb8-432a-a73a-c0246bd182f2",
   "metadata": {},
   "source": [
    "## text_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c96c259-8872-45c6-b0dc-31cc267bfa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_encode(df, column, df_type):\n",
    "    \n",
    "    if df_type == 'text':  # Check if it's a text DataFrame\n",
    "        df['type_text'] = df[column].apply(lambda x: 'statement' if x == 0 else 'minutes')\n",
    "\n",
    "    elif df_type == 'rates':  # Check if it's a rates DataFrame\n",
    "        df['rate_change'] = df[column].diff()\n",
    "        df['rate_change_text'] = df['rate_change'].apply(lambda x: 'up' if x > 0 else ('down' if x < 0 else 'no change')).astype(str)\n",
    "        \n",
    "    else:  # Handle incorrect df_type values\n",
    "        return \"Error: Invalid df_type. Choose 'text' or 'rates'.\"\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4c67a5c-d7d5-42a4-9a7c-0ac5a77b565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = text_encode(text_df, 'type', 'text')\n",
    "rates_df = text_encode (rates_df, 'rate', 'rates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca8fe485-2e1c-40dd-b616-9555fa7687fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9973    statement\n",
      "9969    statement\n",
      "9972    statement\n",
      "9971    statement\n",
      "9970    statement\n",
      "Name: type_text, dtype: object\n",
      "71    no change\n",
      "70    no change\n",
      "69    no change\n",
      "68    no change\n",
      "67    no change\n",
      "Name: rate_change_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(text_df['type_text'].head())\n",
    "print(rates_df['rate_change_text'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7625581-ba88-4609-b32d-d4c426fe5e49",
   "metadata": {},
   "source": [
    "## sliding_window and group_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce8a001b-defb-426d-8060-e06e1aadc136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e259ab99-487d-4569-a79e-8b584ab770e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_text(rate_date, text_df, date_diff):\n",
    "    window_size = timedelta(days=date_diff)\n",
    "\n",
    "    # Filter texts that occurred before the rate decision\n",
    "    valid_texts = text_df[text_df['date'] < rate_date]\n",
    "\n",
    "    # Apply sliding window: Get texts within the specified window size before rate_date\n",
    "    texts_in_window = valid_texts[valid_texts['date'] >= rate_date - window_size]\n",
    "\n",
    "    # Combine the texts\n",
    "    grouped_texts = ' '.join(texts_in_window['text'])\n",
    "    \n",
    "    return grouped_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63825504-ef0f-4c8b-a821-4c13bf84c6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(rates_df, text_df):\n",
    "    \n",
    "    rates_df = rates_df.copy()\n",
    "    \n",
    "    # Calculate the difference between consecutive rate decisions to determine dynamic window size\n",
    "    rates_df['next_date'] = rates_df['date'].shift(-1)\n",
    "    rates_df['date_diff'] = (rates_df['next_date'] - rates_df['date']).dt.days\n",
    "    \n",
    "    # Corrects for NaNs since we are subtracting time deltas\n",
    "    rates_df['date_diff'] = rates_df['date_diff'].fillna(0).astype(int)\n",
    "\n",
    "    # isolate statements and minutes as they occurr at different times relative to previous decisions\n",
    "    statement_df = text_df[text_df['type_text'] == 'statement']\n",
    "    minutes_df = text_df[text_df['type_text'] == 'minutes']    \n",
    "\n",
    "    pairing_data  = []\n",
    "\n",
    "    for _, rate_row in rates_df.iterrows():\n",
    "        rate_date = rate_row['date']\n",
    "        rate = rate_row['rate_change_text']\n",
    "        date_diff = rate_row['date_diff']\n",
    "        \n",
    "        grouped_statements = group_text(rate_date, statement_df, date_diff)\n",
    "        grouped_minutes = group_text(rate_date, minutes_df, date_diff)\n",
    "    \n",
    "        # Add the data to pairing_df\n",
    "        pairing_data.append({\n",
    "            'decision': rate,\n",
    "            'date': rate_date,\n",
    "            'grouped_statements': grouped_statements,\n",
    "            'grouped_minutes': grouped_minutes,\n",
    "            'window_size_days': date_diff  # Store the dynamic window size for reference\n",
    "        })\n",
    "\n",
    "    pairing_df = pd.DataFrame(pairing_data)\n",
    "    pairing_df = pairing_df.set_index(\"date\")\n",
    "    \n",
    "    return pairing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9d26dc8e-46a0-42f1-a402-6b73aeff0a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             decision                                 grouped_statements  \\\n",
      "date                                                                       \n",
      "2015-01-28  no change  \\r\\n       For media inquiries, call 202-452-2...   \n",
      "2015-03-18  no change  \\nSubmission of Tender\\nParticipants must subm...   \n",
      "2015-04-29  no change  \\r\\n       Information received since the Fede...   \n",
      "2015-06-17  no change  \\r\\n       The Federal Open Market Committee o...   \n",
      "2015-07-29  no change  \\r\\n      Voting for the FOMC monetary policy ...   \n",
      "\n",
      "                                              grouped_minutes  \\\n",
      "date                                                            \n",
      "2015-01-28                                                      \n",
      "2015-03-18                                                      \n",
      "2015-04-29  Michael Dotsey, Craig S. Hakkio, Evan F. Koeni...   \n",
      "2015-06-17                                                      \n",
      "2015-07-29  Glenn Follette and Paul A. Smith, Assistant Di...   \n",
      "\n",
      "            window_size_days  \n",
      "date                          \n",
      "2015-01-28                49  \n",
      "2015-03-18                42  \n",
      "2015-04-29                49  \n",
      "2015-06-17                42  \n",
      "2015-07-29                50  \n"
     ]
    }
   ],
   "source": [
    "pairing_df = sliding_window(rates_df, text_df)\n",
    "print(pairing_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df30a37-9244-493b-81db-25a27f8cf139",
   "metadata": {},
   "source": [
    "## ordinal_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3a4c31b9-353c-4877-992f-1dd8bdb6f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2a020306-643d-419f-b953-486ac195204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_encode(df, column):\n",
    "    \n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    df[f'{column}_encoded'] = ordinal_encoder.fit_transform(df[[column]]).astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae2e9d6b-9883-4d51-864e-aac108ebd8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "2015-01-28    1\n",
      "2015-03-18    1\n",
      "2015-04-29    1\n",
      "2015-06-17    1\n",
      "2015-07-29    1\n",
      "Name: decision_encoded, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pairing_df = ordinal_encode (pairing_df, 'decision')\n",
    "print(pairing_df['decision_encoded'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55846154-5608-4967-9af2-926b6bf0afd4",
   "metadata": {},
   "source": [
    "## FinBERT_vectorization and finalize_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "18cc0d53-9484-4994-8a64-821e990e11b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b1d0008a-7dae-43ce-991a-76166f48693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FinBERT_vectorizaion(text):\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "    model = AutoModel.from_pretrained(\"ProsusAI/finbert\")\n",
    "    \n",
    "    # Ensure text is not empty or NaN\n",
    "    if pd.isna(text) or text.strip() == \"\":\n",
    "        return np.zeros((768,))  # Return a zero-vector if input is empty or NaN\n",
    "    \n",
    "    # Proceed with tokenization and embedding generation\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    return outputs.last_hidden_state[:, 0, :].numpy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "72ff8574-35f8-4c59-9777-5cb520631fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_df(df):\n",
    "    \n",
    "    df['statement_vectorized'] = df['grouped_statements'].apply(lambda x: FinBERT_vectorizaion(str(x)))\n",
    "    df['minutes_vectorized'] = df['grouped_minutes'].apply(lambda x: FinBERT_vectorizaion(str(x)))\n",
    "    \n",
    "    \n",
    "    # since we are dealing with NaNs in minutes_embedding, we add a conditionality when stacking the two arrays\n",
    "    # this makes sure the size of the array is the same even if we generat a 1D 0 array for NaNs previously\n",
    "    df['combined_vectorization'] = df.apply(\n",
    "        lambda row: np.hstack((row['statement_vectorized'].squeeze(), \n",
    "                           (row['minutes_vectorized'].squeeze() if isinstance(row['minutes_vectorized'], np.ndarray) else np.zeros(768)))), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b6913490-f162-4805-9185-2136ca157e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = finalize_df(pairing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "11edf200-a2d7-4fc5-9734-5e8d4fa4399a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             decision                                 grouped_statements  \\\n",
      "date                                                                       \n",
      "2015-01-28  no change  \\r\\n       For media inquiries, call 202-452-2...   \n",
      "2015-03-18  no change  \\nSubmission of Tender\\nParticipants must subm...   \n",
      "2015-04-29  no change  \\r\\n       Information received since the Fede...   \n",
      "2015-06-17  no change  \\r\\n       The Federal Open Market Committee o...   \n",
      "2015-07-29  no change  \\r\\n      Voting for the FOMC monetary policy ...   \n",
      "\n",
      "                                              grouped_minutes  \\\n",
      "date                                                            \n",
      "2015-01-28                                                      \n",
      "2015-03-18                                                      \n",
      "2015-04-29  Michael Dotsey, Craig S. Hakkio, Evan F. Koeni...   \n",
      "2015-06-17                                                      \n",
      "2015-07-29  Glenn Follette and Paul A. Smith, Assistant Di...   \n",
      "\n",
      "            window_size_days  decision_encoded  \\\n",
      "date                                             \n",
      "2015-01-28                49                 1   \n",
      "2015-03-18                42                 1   \n",
      "2015-04-29                49                 1   \n",
      "2015-06-17                42                 1   \n",
      "2015-07-29                50                 1   \n",
      "\n",
      "                                         statement_vectorized  \\\n",
      "date                                                            \n",
      "2015-01-28  [[-0.24246012, 0.67152435, -0.20416914, -0.289...   \n",
      "2015-03-18  [[-0.07346612, 0.82941, -0.24438372, -0.567741...   \n",
      "2015-04-29  [[-0.092187196, -0.2836279, -0.6326303, -0.354...   \n",
      "2015-06-17  [[0.060003556, 0.84255415, -0.253191, -0.20966...   \n",
      "2015-07-29  [[0.06376937, -0.35077733, -0.35831827, -0.235...   \n",
      "\n",
      "                                           minutes_vectorized  \\\n",
      "date                                                            \n",
      "2015-01-28  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "2015-03-18  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "2015-04-29  [[-0.45089048, 1.0477439, -0.48942053, -0.1629...   \n",
      "2015-06-17  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "2015-07-29  [[0.17244048, -0.17300418, 0.04781793, 0.05584...   \n",
      "\n",
      "                                       combined_vectorization  \n",
      "date                                                           \n",
      "2015-01-28  [-0.24246011674404144, 0.6715243458747864, -0....  \n",
      "2015-03-18  [-0.07346612215042114, 0.8294100165367126, -0....  \n",
      "2015-04-29  [-0.092187196, -0.2836279, -0.6326303, -0.3542...  \n",
      "2015-06-17  [0.060003556311130524, 0.8425541520118713, -0....  \n",
      "2015-07-29  [0.06376937, -0.35077733, -0.35831827, -0.2351...  \n"
     ]
    }
   ],
   "source": [
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463051d3-297c-420a-a692-d2f6b6ee0bda",
   "metadata": {},
   "source": [
    "## train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f15c5dda-5aba-4681-ae95-c01bbe54b0a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mparams\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TEST_SIZE, RANDOM_STATE\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'params'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af00d1b3-2244-4d09-84ec-969c0a00eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_train_test_split(df, test_size=0.2, random_state=42):\n",
    "    \"\"\" Splits the dataset into training and testing sets. \"\"\"\n",
    "\n",
    "    # Convert columns to NumPy arrays\n",
    "    X = np.vstack(df['combined_vectorization'].values)\n",
    "    y = df['decision_encoded'].values\n",
    "\n",
    "    # Split the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test  # ✅ Returns only 4 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b6468be6-0507-4d79-bffa-032bbce05add",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = custom_train_test_split(final_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e032e501-e3b9-401f-a3e5-ce949934cf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.46038529  0.1941262  -0.56941366 ... -0.11998674  1.01999545\n",
      "   0.59468979]\n",
      " [ 0.30797532 -0.30749211 -0.43068966 ...  0.05326387  0.83187574\n",
      "   0.34394997]\n",
      " [-0.22082192  0.55722332  0.25929168 ... -0.17048459  0.4922418\n",
      "   0.46881706]\n",
      " ...\n",
      " [-0.94639862  0.47974601 -0.16530991 ... -0.50802386 -0.38364428\n",
      "   0.55841517]\n",
      " [-0.12968168 -0.0050654  -0.41801387 ... -0.47364542  0.03962266\n",
      "   0.66211003]\n",
      " [-0.01522618  0.37421858 -0.64247054 ... -0.06257439  0.06237637\n",
      "   0.34195045]]\n",
      "[1 1 1 1 1 2 1 1 1 2 2 1 0 1 1 1 2 2 2 1 1 2 1 2 0 1 1 1 0 2 1 1 2 2 0 1 1\n",
      " 1 2 2 1 1 1 2 0 2 1 2 1 1 1 1 2 1 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc1d02c-11f6-43eb-af74-204e36ee35b5",
   "metadata": {},
   "source": [
    "## class_weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5a554fbc-52a3-4250-a2ab-45a5232372e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_weighting (y_train):\n",
    "    # Count occurrences in y_train\n",
    "    class_counts = np.bincount(y_train)  # Ensure ordering is correct\n",
    "\n",
    "    # Compute class weights\n",
    "    class_weights = torch.tensor([1 / count for count in class_counts], dtype=torch.float32)\n",
    "    \n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "68c6a6dd-3504-4991-bf03-c8483cd22d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weighting(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8788b1e6-0895-43f5-bfd9-b992b06f5b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2000, 0.0294, 0.0556])\n"
     ]
    }
   ],
   "source": [
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829faf23-8fad-4ecf-bed8-e3f74b5faffb",
   "metadata": {},
   "source": [
    "## tensor_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7484a4de-efd3-48b8-9407-29556b7ba57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_conversion(X, y):\n",
    "    \n",
    "    X_train_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "    X_train_tensor = X_train_tensor.unsqueeze(1)\n",
    "    y_train_tensor = torch.tensor(y, dtype=torch.long)\n",
    "    \n",
    "    return X_train_tensor, y_train_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0a868d9e-35a1-4bc1-8eeb-d7ba5e06c2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor, y_train_tensor = tensor_conversion(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "07f750e5-0852-458a-99ed-a054a0be820d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([57, 1, 1536])\n",
      "torch.Size([57])\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tensor.shape)\n",
    "print(y_train_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3feb6fb9-ed10-4b57-ad49-cddb25a9e6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 1, 1536])\n",
      "torch.Size([15])\n"
     ]
    }
   ],
   "source": [
    "X_test_tensor, y_test_tensor = tensor_conversion(X_test, y_test)\n",
    "print(X_test_tensor.shape)\n",
    "print(y_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9f90e0-359a-46b3-82ff-9fda134a90e1",
   "metadata": {},
   "source": [
    "## initialize_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "06cf09dd-6240-4119-88e0-d2cb6b5fa2bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mparams\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m INPUT_DIM,HIDDEN_DIM, OUTPUT_DIM, K, LEARNING_RATE, RANDOM_STATE, EPOCHS\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mencoders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m class_weighting\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'params'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from encoders import class_weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "62d370f7-8b2b-4e7d-85d4-0fb2015c1cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = X_train.shape[1]  # Same as embedding size\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = 3  # For multiclass classification (up, down, no change)\n",
    "K = 5 \n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 10\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d901d6d3-485e-4074-98ba-63d38d601c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # Multiply by 2 for bidirectional\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        last_out = lstm_out[:, -1, :]  # Take the last time step's output\n",
    "        return self.fc(self.relu(last_out))\n",
    "        \n",
    "def initialize_model(X_train, hidden_dim, output_dim):\n",
    "    \n",
    "    input_dim = X_train.shape[1]\n",
    "    \n",
    "    model = BiLSTM(input_dim, hidden_dim, output_dim)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "694d313c-8c96-4e30-8c58-b871cbea0176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM(\n",
      "  (lstm): LSTM(1536, 128, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = initialize_model(X_train, HIDDEN_DIM, OUTPUT_DIM)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e155d84-d6a1-4ae8-8c4e-1ca47ac6577c",
   "metadata": {},
   "source": [
    "## compile_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7c239f5a-dc8b-48f3-856a-25448df64278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(y_train, model, learning_rate=LEARNING_RATE):\n",
    "    \n",
    "    class_weights = class_weighting (y_train)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    return criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "49ea638c-0b65-47d3-9544-0bf7392a1277",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion, optimizer = compile_model(y_train, model, learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "affbf6a2-cb67-4624-96b4-f7fc685072cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossEntropyLoss() Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2909dc0-0bac-4e60-a0f0-1fa1ee58befe",
   "metadata": {},
   "source": [
    "## evaluate_model and train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "230f054e-128d-4c8b-a71f-62811f6ddbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test_tensor, y_test_tensor):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient computation for efficiency\n",
    "        outputs = model(X_test_tensor)  # Get the model's output\n",
    "\n",
    "        logits = outputs  # These are the raw predictions (logits)\n",
    "\n",
    "        # Get the predicted class (highest logit)\n",
    "        predicted_labels = torch.argmax(logits, dim=1)\n",
    "        \n",
    "    # Compute accuracy by comparing predicted labels to true labels\n",
    "    accuracy = accuracy_score(y_test_tensor.numpy(), predicted_labels.numpy())\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d655899d-33bc-40d7-a7da-2e16bacd4ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13333333333333333\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate_model(model, X_test_tensor, y_test_tensor)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "95fb17d6-a813-45d0-a218-c1d3910aae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train_tensor, y_train_tensor, y_train, n_splits=K):\n",
    "    \n",
    "    kf = KFold(n_splits=K, shuffle=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "    fold_accuracies =[]\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_tensor, y_train_tensor)):\n",
    "        print(f\"Training fold {fold + 1}/{K}...\")\n",
    "\n",
    "        # Split data into training and validation sets for this fold\n",
    "        X_train_fold, X_val_fold = X_train_tensor[train_idx], X_train_tensor[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train_tensor[train_idx], y_train_tensor[val_idx]\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        X_train_fold_tensor = torch.tensor(X_train_fold, dtype=torch.float32)\n",
    "        y_train_fold_tensor = torch.tensor(y_train_fold, dtype=torch.long)\n",
    "        X_val_fold_tensor = torch.tensor(X_val_fold, dtype=torch.float32)\n",
    "        y_val_fold_tensor = torch.tensor(y_val_fold, dtype=torch.long)\n",
    "\n",
    "        # Initialize the model, criterion, and optimizer\n",
    "        model = initialize_model(X_train, hidden_dim=128, output_dim=3)\n",
    "        criterion, optimizer = compile_model(y_train, model, learning_rate = LEARNING_RATE)\n",
    "\n",
    "        # Train the model on this fold\n",
    "        model.train()  # Set model to training mode\n",
    "        for epoch in range(EPOCHS):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train_fold_tensor)\n",
    "            loss = criterion(outputs, y_train_fold_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        # Evaluate the model on the validation set\n",
    "        accuracy = evaluate_model(model, X_val_fold_tensor, y_val_fold_tensor)\n",
    "        print(f\"Fold {fold + 1} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # Save the accuracy for this fold\n",
    "        fold_accuracies.append(accuracy)\n",
    "\n",
    "        # Calculate average accuracy across all folds\n",
    "        average_accuracy = np.mean(fold_accuracies)\n",
    "        print(f\"\\nAverage Cross-Validation Accuracy: {average_accuracy:.4f}\")\n",
    "\n",
    "    return model, average_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3a218b0d-8697-49ef-a5d2-b18bcc9e1d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/5...\n",
      "Fold 1 Accuracy: 0.4167\n",
      "\n",
      "Average Cross-Validation Accuracy: 0.4167\n",
      "Training fold 2/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28246/161865244.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_fold_tensor = torch.tensor(X_train_fold, dtype=torch.float32)\n",
      "/tmp/ipykernel_28246/161865244.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train_fold_tensor = torch.tensor(y_train_fold, dtype=torch.long)\n",
      "/tmp/ipykernel_28246/161865244.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val_fold_tensor = torch.tensor(X_val_fold, dtype=torch.float32)\n",
      "/tmp/ipykernel_28246/161865244.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_val_fold_tensor = torch.tensor(y_val_fold, dtype=torch.long)\n",
      "/tmp/ipykernel_28246/161865244.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_fold_tensor = torch.tensor(X_train_fold, dtype=torch.float32)\n",
      "/tmp/ipykernel_28246/161865244.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train_fold_tensor = torch.tensor(y_train_fold, dtype=torch.long)\n",
      "/tmp/ipykernel_28246/161865244.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val_fold_tensor = torch.tensor(X_val_fold, dtype=torch.float32)\n",
      "/tmp/ipykernel_28246/161865244.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_val_fold_tensor = torch.tensor(y_val_fold, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Accuracy: 0.4167\n",
      "\n",
      "Average Cross-Validation Accuracy: 0.4167\n",
      "Training fold 3/5...\n",
      "Fold 3 Accuracy: 0.3636\n",
      "\n",
      "Average Cross-Validation Accuracy: 0.3990\n",
      "Training fold 4/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28246/161865244.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_fold_tensor = torch.tensor(X_train_fold, dtype=torch.float32)\n",
      "/tmp/ipykernel_28246/161865244.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train_fold_tensor = torch.tensor(y_train_fold, dtype=torch.long)\n",
      "/tmp/ipykernel_28246/161865244.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val_fold_tensor = torch.tensor(X_val_fold, dtype=torch.float32)\n",
      "/tmp/ipykernel_28246/161865244.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_val_fold_tensor = torch.tensor(y_val_fold, dtype=torch.long)\n",
      "/tmp/ipykernel_28246/161865244.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_fold_tensor = torch.tensor(X_train_fold, dtype=torch.float32)\n",
      "/tmp/ipykernel_28246/161865244.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train_fold_tensor = torch.tensor(y_train_fold, dtype=torch.long)\n",
      "/tmp/ipykernel_28246/161865244.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val_fold_tensor = torch.tensor(X_val_fold, dtype=torch.float32)\n",
      "/tmp/ipykernel_28246/161865244.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_val_fold_tensor = torch.tensor(y_val_fold, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Accuracy: 0.7273\n",
      "\n",
      "Average Cross-Validation Accuracy: 0.4811\n",
      "Training fold 5/5...\n",
      "Fold 5 Accuracy: 0.5455\n",
      "\n",
      "Average Cross-Validation Accuracy: 0.4939\n",
      "BiLSTM(\n",
      "  (lstm): LSTM(1536, 128, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
      "  (relu): ReLU()\n",
      ") 0.49393939393939396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28246/161865244.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_fold_tensor = torch.tensor(X_train_fold, dtype=torch.float32)\n",
      "/tmp/ipykernel_28246/161865244.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train_fold_tensor = torch.tensor(y_train_fold, dtype=torch.long)\n",
      "/tmp/ipykernel_28246/161865244.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val_fold_tensor = torch.tensor(X_val_fold, dtype=torch.float32)\n",
      "/tmp/ipykernel_28246/161865244.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_val_fold_tensor = torch.tensor(y_val_fold, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "model, average_accuracy = train_model(X_train_tensor, y_train_tensor, y_train, n_splits=K)\n",
    "print(model, average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165776f8-48b1-4d14-8a92-e7b39c915b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FED-Predictor",
   "language": "python",
   "name": "fed-predictor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
